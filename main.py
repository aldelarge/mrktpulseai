from scraper import scrape_yahoo_finance
from scraper import scrape_yahoo_indices
from scraper import scrape_cnbc_news
from scraper import scrape_marketwatch
from scraper import scrape_yahoo_sectors
from sentiment_analysis import analyze_daily_sentiment_gpt, analyze_weekly_sentiment_gpt
from polygon_api import get_index_snapshot
from polygon_api import format_etf_data
from send_email import send_email
from markdown import markdown_to_html, format_market_summary
from stock_news_api import fetch_top_headlines, format_market_analysis
import json
import os
from datetime import datetime
import asyncio
from webapp import create_app, db
from webapp.models import User 



WEEKLY_DATA_FILE = "weekly_data.json"
WEEKLY_REPORTS_FILE = "weekly_reports.json"

app = create_app()

current_day = datetime.now().weekday()

def format_sector_performance(sectors):
    formatted = "\n".join([f"{sector['sector']}: {sector['percent_change']}" for sector in sectors])
    return f"Sector Performance:\n{formatted}"
# For storing the weekly report
def save_weekly_report(report):
    """Save the weekly report generated by GPT-4 for future reference."""
    weekly_report = {
        "date": datetime.now().strftime("%Y-%m-%d"),  # Add the current date for easy identification
        "report": report
    }

    # Load existing reports or initialize an empty list
    if os.path.exists(WEEKLY_REPORTS_FILE):
        with open(WEEKLY_REPORTS_FILE, "r") as file:
            weekly_reports = json.load(file)
    else:
        weekly_reports = []

    weekly_reports.append(weekly_report)

    with open(WEEKLY_REPORTS_FILE, "w") as file:
        json.dump(weekly_reports, file, indent=4)

    print("ðŸ“Œ Weekly market report saved.")

# Function to handle daily tasks (scraping, sentiment analysis, saving data)
async def daily_tasks():
    today = datetime.now().strftime("%Y-%m-%d")

    # Scraping data
    # news1 = scrape_yahoo_finance()
    # news2 = scrape_cnbc_news()
    # news3 = scrape_marketwatch()
    news = fetch_top_headlines(limit=100)
    sectors_data = scrape_yahoo_sectors()
    sector_summary = format_sector_performance(sectors_data)
    snapshot = get_index_snapshot()
    indices = format_etf_data(snapshot)
    # print(indices)
    # print(sector_summary)

    # Validate that news lists are actually lists
    # if not isinstance(news1, list) or not isinstance(news2, list):
    #     print("Error: One of the news sources did not return a valid list.")
    #     return  
    # if not news1:
    #     print("Warning: Yahoo Finance scraper returned no headlines.")
    # if not news2:
    #     print("Warning: CNBC scraper returned no headlines.")
    # if not news3:
    #     print("Warning: Marketwatch scraper returned no headlines.")
    if not indices:
        print("Warning: Indices data scraper returned no data.")
    if not sectors_data:
        print("Warning: Sectors data scraper returned no data.")

    # Extract headlines from the scraped data
    # yahoo_headlines = [article["headline"] for article in news1 if isinstance(article, dict)]
    # cnbc_headlines = [article["headline"] for article in news2 if isinstance(article, dict)]
    # marketwatch_headlines = [article["headline"] for article in news3 if isinstance(article, dict)]

    # Combine all headlines into one list
    headlines = format_market_analysis(news)
    # print(headlines)
    if headlines:
        sentiment_summary = analyze_daily_sentiment_gpt(headlines, indices, sector_summary)
        # print(f"\n {sentiment_summary}")

        # Save today's data
        # save_daily_newsletter(today, indices, sector_summary, sentiment_summary)
        
        # key_points = extract_key_points(sentiment_summary)
        # store_summary_key_points(key_points)

        
        return sentiment_summary
    else:
        print("No news articles found.")

# Function to handle weekly tasks (reading weekly data, scraping weekend news, generating weekly summary)
async def weekly_tasks():
    today = datetime.now().strftime("%Y-%m-%d")
    WEEKLY_DATA_FILE = "weekly_data.json"

    # Get the weekly data from the JSON file
    if os.path.exists(WEEKLY_DATA_FILE):
        with open(WEEKLY_DATA_FILE, "r") as file:
            weekly_data = json.load(file)
    else:
        print("No weekly data found.")
        return

    # Scrape the weekend news (Friday, Saturday, Sunday)
    weekend_news1 = scrape_yahoo_finance()
    weekend_news2 = scrape_cnbc_news()
    weekend_news3 = scrape_marketwatch()

    # Extract headlines for the weekend news
    weekend_yahoo_headlines = [article["headline"] for article in weekend_news1 if isinstance(article, dict)]
    weekend_cnbc_headlines = [article["headline"] for article in weekend_news2 if isinstance(article, dict)]
    weekend_marketwatch_headlines = [article["headline"] for article in weekend_news3 if isinstance(article, dict)]

    # Combine the weekend headlines into one list
    weekend_headlines = weekend_yahoo_headlines + weekend_cnbc_headlines + weekend_marketwatch_headlines

    if weekend_headlines:
        sentiment_summary = analyze_weekly_sentiment_gpt(weekend_headlines, weekly_data)
        print(f"\n {sentiment_summary}")

        # Save the weekly report
        save_weekly_report(sentiment_summary)
        return sentiment_summary
    else:
        print("No weekend news found.")


async def main():
    print("Starting main function...")
    
    daily_market_update = await daily_tasks()

    dmu_formatted = format_market_summary(daily_market_update)

    print(f"Market Update: {daily_market_update}") 

    with app.app_context():
        # Retrieve all users' email addresses from the database
        users = User.query.all()  # Fetch all users from the database
        recipients = [user.email for user in users if user.subscription_status == "active"]

    print("sending emails individually....")
    # Loop through each recipient and send the email individually
    for recipient in recipients:
        try:
            result = send_email("Daily Market Update", dmu_formatted, recipient)  # Send individual email to each recipient
            print(result)  # Print success message
        except Exception as e:
            print(f"Error: {e}")  # Print error message if something goes wrong
        
    print("Email Sent! (:")


    # Run weekly tasks (can be scheduled to run every Sunday at noon)
    # weekly_tasks()

if __name__ == "__main__":
    asyncio.run(main())

from scraper import scrape_yahoo_finance
from scraper import scrape_yahoo_indices
from scraper import scrape_cnbc_news
from scraper import scrape_marketwatch
from scraper import scrape_yahoo_sectors
from sentiment_analysis import analyze_sentiment_gpt
import json
import os
from datetime import datetime

WEEKLY_DATA_FILE = "weekly_data.json"
WEEKLY_REPORTS_FILE = "weekly_reports.json"

def format_sector_performance(sectors):
    formatted = "\n".join([f"{sector['sector']}: {sector['percent_change']}" for sector in sectors])
    return f"Sector Performance:\n{formatted}"

def save_daily_data(date, indices, sectors, headlines, market_summary):
    """Save the day's market data into a JSON file for weekly aggregation."""
    daily_data = {
        "date": date,
        "indices": indices,
        "sectors": sectors,
        "headlines": headlines,
        "market_summary": market_summary
    }

    # Load existing data or initialize an empty list
    if os.path.exists(WEEKLY_DATA_FILE):
        with open(WEEKLY_DATA_FILE, "r") as file:
            weekly_data = json.load(file)
    else:
        weekly_data = []

    weekly_data.append(daily_data)  # Append today's data

    with open(WEEKLY_DATA_FILE, "w") as file:
        json.dump(weekly_data, file, indent=4)

    print(f"âœ… Market data for {date} saved successfully.")

def save_weekly_report(report):
    """Save the weekly report generated by GPT-4 for future reference."""
    if os.path.exists(WEEKLY_REPORTS_FILE):
        with open(WEEKLY_REPORTS_FILE, "r") as file:
            weekly_reports = json.load(file)
    else:
        weekly_reports = []

    weekly_reports.append({
        "date": datetime.now().strftime("%Y-%m-%d"),
        "report": report
    })

    with open(WEEKLY_REPORTS_FILE, "w") as file:
        json.dump(weekly_reports, file, indent=4)

    print("ðŸ“Œ Weekly market report saved.")

def main():
    today = datetime.now().strftime("%Y-%m-%d")

    news1 = scrape_yahoo_finance()
    news2 = scrape_cnbc_news()
    news3 = scrape_marketwatch()
    indices = scrape_yahoo_indices()
    sectors_data = scrape_yahoo_sectors()
    sector_summary = format_sector_performance(sectors_data)

    print(sector_summary)

    # Validate that news lists are actually lists
    if not isinstance(news1, list) or not isinstance(news2, list,):
        print("Error: One of the news sources did not return a valid list.")
        return  
    if not news1:
        print("Warning: Yahoo Finance scraper returned no headlines.")
    if not news2:
        print("Warning: CNBC scraper returned no headlines.")
    if not news3:
        print("Warning: marketwatch scraper returned no headlines.")
    if not indices:
        print("Warning: Indices data scraper returned no data.")
    if not sectors_data:
        print("Warning: Sectors data scraper returned no data.")



    # Extract only headlines from the scraped data
    yahoo_headlines = [article["headline"] for article in news1 if isinstance(article, dict)]
    cnbc_headlines = [article["headline"] for article in news2 if isinstance(article, dict)]
    marketwatch_headlines = [article["headline"] for article in news3 if isinstance(article, dict)]

    # Combine all headlines into one list
    headlines = yahoo_headlines + cnbc_headlines + marketwatch_headlines

    if headlines:
        sentiment_summary = analyze_sentiment_gpt(headlines, indices, sector_summary)
        print(f"\n {sentiment_summary}")

         # Save today's data
        save_daily_data(today, indices, sectors_data, headlines, sentiment_summary)

    else:
        print("No news articles found.")

if __name__ == "__main__":
    main()